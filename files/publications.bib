@inproceedings{Forest2018,
abstract = {A major application of data analytics for aircraft engine manufacturers is engine health monitoring, which consists in improving availability and operation of engines by leveraging operational data and past events. Traditional tools can no longer handle the increasing volume and velocity of data collected on modern aircraft. We propose a generic and scalable pipeline for large-scale analytics of operational data from a recent type of aircraft engine, oriented towards health monitoring applications. Based on Hadoop and Spark, our approach enables domain experts to scale their algorithms and extract features from tens of thousands of flights stored on a cluster. All computations are performed using the Spark framework, however custom functions and algorithms can be integrated without knowledge of distributed programming. Unsupervised learning algorithms are integrated for clustering and dimensionality reduction of the flight features, in order to allow efficient visualization and interpretation through a dedicated web application. The use case guiding our work is a methodology for engine fleet monitoring with a self-organizing map. Finally, this pipeline is meant to be end-to-end, fully customizable and ready for use in an industrial setting.},
author = {Forest, Florent and Lacaille, J{\'{e}}r{\^{o}}me and Lebbah, Mustapha and Azzag, Hanane},
booktitle = {IEEE International Conference on Big Data},
doi = {10.1109/BigData.2018.8622297},
isbn = {9781538650356},
keywords = {big data,aircraft engine,aviation,generic,hadoop,health monitoring,scalable,spark},
title = {{A Generic and Scalable Pipeline for Large-Scale Analytics of Continuous Aircraft Engine Data}},
year = {2018},
url_Link = {https://ieeexplore.ieee.org/document/8622297},
url_Paper = {IEEEBigData-2018-ForestLacailleLebbahAzzag-full-paper.pdf}
}
@inproceedings{Forest2019a,
abstract = {Recent research has demonstrated how deep neural networks are able to learn representations to improve data clustering. By considering representation learning and clustering as a joint task, models learn clustering-friendly spaces and achieve superior performance, com- pared with standard two-stage approaches where dimensionality reduc- tion and clustering are performed separately. We extend this idea to topology-preserving clustering models, known as self-organizing maps (SOM). First, we present the Deep Embedded Self-Organizing Map (DE- SOM), a model composed of a fully-connected autoencoder and a custom SOM layer, where the SOM code vectors are learnt jointly with the au- toencoder weights. Then, we show that this generic architecture can be extended to image and sequence data by using convolutional and recur- rent architectures, and present variants of these models. First results demonstrate advantages of the DESOM architecture in terms of cluster- ing performance, visualization and training time.},
author = {Forest, Florent and Lebbah, Mustapha and Azzag, Hanane and Lacaille, J{\'{e}}r{\^{o}}me},
booktitle = {Workshop on Learning Data Representations for Clustering (LDRC), PAKDD},
doi = {10.1007/978-3-030-26142-9_10},
keywords = {autoencoder,clustering,deep learning,representation learning,self-organizing map},
title = {{Deep Architectures for Joint Clustering and Visualization with Self-Organizing Maps}},
year = {2019},
url_Link = {https://link.springer.com/chapter/10.1007/978-3-030-26142-9_10},
url_Paper = {LDRC-2019-DeepArchitecturesJointClusteringVisualization-full-paper.pdf}
}
@inproceedings{Forest2019,
abstract = {In the wake of recent advances in joint clustering and deep learning, we introduce the Deep Embedded Self-Organizing Map, a model that jointly learns representations and the code vectors of a self-organizing map. Our model is composed of an autoencoder and a custom SOM layer that are optimized in a joint training procedure, motivated by the idea that the SOM prior could help learning SOM-friendly representations. We eval- uate SOM-based models in terms of clustering quality and unsupervised clustering accuracy, and study the benefits of joint training.},
author = {Forest, Florent and Lebbah, Mustapha and Azzag, Hanane and Lacaille, J{\'{e}}r{\^{o}}me},
booktitle = {European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning (ESANN)},
keywords = {autoencoder,clustering,deep learning,representation learning,self-organizing map},
title = {{Deep Embedded SOM: Joint Representation Learning and Self-Organization}},
year = {2019},
url_Link = {https://www.esann.org/proceedings/2019},
url_Paper = {https://www.elen.ucl.ac.be/Proceedings/esann/esannpdf/es2019-30.pdf},
url_Slides = {ESANN-2019-DeepEmbeddedSOM-pres.pdf},
url_Code = {https://github.com/FlorentF9/DESOM}
}
@misc{Forest2019b,
author = {Forest, Florent},
title = {{Poster: Clustering de donn{\'{e}}es massives - Analyse de donn{\'{e}}es de turbofans}},
year = {2019},
source_type = {poster},
url_Paper = {poster-journeeED-2019.pdf}
}
@inproceedings{Forest2020d,
abstract = {Dans la lign{\'{e}}e des r{\'{e}}centes avanc{\'{e}}es en apprentissage profond de repr{\'{e}}sentations pour le clustering, ce travail (pr{\'{e}}c{\'{e}}demment publi{\'{e}} en anglais) pr{\'{e}}sente le mod{\`{e}}le DESOM (Deep Embedded SOM), combinant l'apprentisssage non supervis{\'{e}} de repr{\'{e}}sentations et d'une carte auto-organis{\'{e}}e de Kohonen (SOM). Le mod{\`{e}}le, compos{\'{e}} d'un auto-encodeur et d'une couche SOM, est optimis{\'{e}} conjointement, an de r{\'{e}}gulariser l'espace latent et am{\'{e}}liorer la performance de la carte SOM. Nous {\'{e}}valuons les performances de classification et de visualisation ainsi que les b{\'{e}}n{\'{e}}fices de l'apprentissage joint. Mots-clef : carte auto-organis{\'{e}}e, clustering, apprentissage profond, auto-encodeur.},
author = {Forest, Florent and Lebbah, Mustapha and Azzag, Hanene and Lacaille, J{\'{e}}r{\^{o}}me},
booktitle = {CAp2020: Conf{\'{e}}rence d'Apprentissage},
keywords = {autoencoder,clustering,deep learning,self-organizing map},
title = {{Carte SOM profonde : Apprentissage joint de repr{\'{e}}sentations et auto-organisation}},
url_Link = {https://hal.archives-ouvertes.fr/hal-02859997},
url_Paper = {https://hal.archives-ouvertes.fr/hal-02859997/document},
year = {2020}
}
@unpublished{Mourer2020,
abstract = {Model selection is a major challenge in non-parametric clustering. There is no universally admitted way to evaluate clustering results for the obvious reason that there is no ground truth against which results could be tested, as in supervised learning. The difficulty to find a universal evaluation criterion is a direct consequence of the fundamentally ill-defined objective of clustering. In this perspective, clustering stability has emerged as a natural and model-agnostic principle: an algorithm should find stable structures in the data. If data sets are repeatedly sampled from the same underlying distribution, an algorithm should find similar partitions. However, it turns out that stability alone is not a well-suited tool to determine the number of clusters. For instance, it is unable to detect if the number of clusters is too small. We propose a new principle for clustering validation: a good clustering should be stable, and within each cluster, there should exist no stable partition. This principle leads to a novel internal clustering validity criterion based on between-cluster and within-cluster stability, overcoming limitations of previous stability-based methods. We empirically show the superior ability of additive noise to discover structures, compared with sampling-based perturbation. We demonstrate the effectiveness of our method for selecting the number of clusters through a large number of experiments and compare it with existing evaluation methods.},
archivePrefix = {arXiv},
arxivId = {arXiv:2006.08530v1},
author = {Mourer, Alex and Forest, Florent and Lebbah, Mustapha and Azzag, Hanane and Lacaille, J{\'{e}}r{\^{o}}me},
eprint = {arXiv:2006.08530v1},
keywords = {validity index,clustering,model selection,stability analysis},
title = {{Selecting the Number of Clusters K with a Stability Trade-off: an Internal Validation Criterion}},
year = {2020},
url_Link = {https://arxiv.org/abs/2006.08530},
url_Paper = {https://arxiv.org/pdf/2006.08530.pdf}
}
@inproceedings{Forest2020,
abstract = {Vibration analysis is an important component of industrial equipment health monitoring. Aircraft engines in particular are complex rotating machines where vibrations, mainly caused by unbalance, misalignment, or damaged bearings, put engine parts under dynamic structural stress. Thus, monitoring the vibratory behavior of engines is essential to detect anomalies and trends, avoid faults and improve availability. Intrinsic properties of parts can be described by the evolution of vibration as function of rotation speed, called a vibration signature. This work presents a methodology for large-scale vibration monitoring on operating civil aircraft engines, based on unsupervised learning algorithms and a flight recorder database. Firstly, we present a pipeline for massive extraction of vibration signatures from raw flight data, consisting in time-domain medium-frequency sensor measurements. Then, signatures are classified and visualized using interpretable self-organized clustering algorithms, yielding a visual cartography of vibration profiles. Domain experts can then extract various insights from resulting models. An abnormal temporal evolution of a signature gives early warning before failure of an engine. In a post-finding situation after an event has occurred, similar at-risk engines are detectable. The approach is global, end-to-end and scalable, which is yet uncommon in our industry, and has been tested on real flight data.},
author = {Forest, Florent and Cochard, Quentin and Noyer, Cecile and Cabut, Adrien and Joncour, Marc and Lacaille, J{\'{e}}r{\^{o}}me and Lebbah, Mustapha and Azzag, Hanene},
booktitle = {Annual Conference of the PHM Society},
keywords = {aircraft engine, vibration analysis, health monitoring, big data, clustering, self-organizing map},
doi = {10.36001/phmconf.2020.v12i1.1131},
title = {{Large-scale Vibration Monitoring of Aircraft Engines from Operational Data using Self-organized Models}},
year = {2020},
url_Link = {https://www.phmpapers.org/index.php/phmconf/article/view/1131},
url_Paper = {https://www.phmpapers.org/index.php/phmconf/article/download/1131/913},
url_Slides = {pres-PHM-2020.pdf},
}
@article{Knodlseder2016,
abstract = {The field of gamma-ray astronomy has seen important progress during the last decade, yet to date no common software framework has been developed for the scientific analysis of gamma-ray telescope data. We propose to fill this gap by means of the GammaLib software, a generic library that we have developed to support the analysis of gamma-ray event data. GammaLib was written in C++ and all functionality is available in Python through an extension module. Based on this framework we have developed the ctools software package, a suite of software tools that enables flexible workflows to be built for the analysis of Imaging Air Cherenkov Telescope event data. The ctools are inspired by science analysis software available for existing high-energy astronomy instruments, and they follow the modular ftools model developed by the High Energy Astrophysics Science Archive Research Center. The ctools were written in Python and C++, and can be either used from the command line via shell scripts or directly from Python. In this paper we present the GammaLib and ctools software versions 1.0 that were released at the end of 2015. GammaLib and ctools are ready for the science analysis of Imaging Air Cherenkov Telescope event data, and also support the analysis of Fermi-LAT data and the exploitation of the COMPTEL legacy data archive. We propose using ctools as the science tools software for the Cherenkov Telescope Array Observatory.},
archivePrefix = {arXiv},
arxivId = {1606.00393},
author = {Kn{\"{o}}dlseder, J. and Mayer, M. and Deil, C. and Cayrou, J. B. and Owen, E. and Kelley-Hoskins, N. and Lu, C. C. and Buehler, R. and Forest, F. and Louge, T. and Siejkowski, H. and Kosack, K. and Gerard, L. and Schulz, A. and Martin, P. and Sanchez, D. and Ohm, S. and Hassan, T. and Brau-Nogu{\'{e}}, S.},
doi = {10.1051/0004-6361/201628822},
eprint = {1606.00393},
issn = {14320746},
journal = {Astronomy and Astrophysics},
keywords = {data analysis,virtual observatory tools},
pages = {1--19},
title = {{GammaLib and ctools: A software framework for the analysis of astronomical gamma-ray data}},
volume = {593},
year = {2016},
url_Link = {https://www.aanda.org/articles/aa/abs/2016/09/aa28822-16/aa28822-16.html},
url_Paper = {https://www.aanda.org/articles/aa/pdf/2016/09/aa28822-16.pdf}
}
@inproceedings{Forest2020a,
abstract = {Time series clustering is a challenging task due to the specificities of this type of data. Temporal correlation and invariance to transformations such as shifting, warping or noise prevent the use of standard data mining methods. Time series clustering has been mostly studied under the angle of finding efficient algorithms and distance metrics adapted to the specific nature of time series data. Much less attention has been devoted to the general problem of model selection. Clustering stability has emerged as a universal and model-agnostic principle for clustering model selection. This principle can be stated as follows: an algorithm should find a structure in the data that is resilient to perturbation by sampling or noise. We propose to apply stability analysis to time series by leveraging prior knowledge on the nature and invariances of the data. These invariances determine the perturbation process used to assess stability. Based on a recently introduced criterion combining between-cluster and within-cluster stability, we propose an invariance-guided method for model selection, applicable to a wide range of clustering algorithms. Experiments conducted on artificial and benchmark data sets demonstrate the ability of our criterion to discover structure and select the correct number of clusters, whenever data invariances are known beforehand.},
author = {Forest, Florent and Mourer, Alex and Lebbah, Mustapha and Azzag, Hanane and Lacaille, J{\'{e}}r{\^{o}}me},
booktitle = {International Conference on Pattern Recognition (ICPR)},
title = {{An Invariance-guided Stability Criterion for Time Series Clustering Validation}},
year = {2020},
url_Paper = {ICPR-2020-InvarianceGuidedStabilityTSC-full-paper.pdf},
url_Slides = {pres-ICPR-2020.pdf}
}
